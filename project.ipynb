{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b23d79af",
   "metadata": {},
   "source": [
    "# Data Splitting and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "434213de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55052a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your original dataset\n",
    "data_dir = r'C:\\Users\\sandeep\\OneDrive\\Desktop\\Navya_files\\Mini Project\\animals_dataset\\animals\\animals'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "931a03c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories for training, validation, and testing data\n",
    "os.makedirs('train', exist_ok=True)\n",
    "os.makedirs('validation', exist_ok=True)\n",
    "os.makedirs('test', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcd5d5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all class directories\n",
    "classes = os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "721dfaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ratio for splitting the data\n",
    "train_ratio = 0.7\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c7d4780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the subdirectories (classes) in your dataset\n",
    "for class_name in os.listdir(data_dir):\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    image_files = os.listdir(class_dir)\n",
    "    random.shuffle(image_files)  # Shuffle the images randomly\n",
    "    # Split the images based on the defined ratios\n",
    "    num_images = len(image_files)\n",
    "    num_train = int(train_ratio * num_images)\n",
    "    num_validation = int(validation_ratio * num_images)\n",
    "\n",
    "    train_images = image_files[:num_train]\n",
    "    validation_images = image_files[num_train:num_train + num_validation]\n",
    "    test_images = image_files[num_train + num_validation:]\n",
    "    \n",
    "    \n",
    "    # Split the images based on the defined ratios\n",
    "    num_images = len(image_files)\n",
    "    num_train = int(train_ratio * num_images)\n",
    "    num_validation = int(validation_ratio * num_images)\n",
    "\n",
    "    train_images = image_files[:num_train]\n",
    "    validation_images = image_files[num_train:num_train + num_validation]\n",
    "    test_images = image_files[num_train + num_validation:]\n",
    "\n",
    "    # Create directories for each class in the train, validation, and test sets\n",
    "    os.makedirs(os.path.join('train', class_name), exist_ok=True)\n",
    "    os.makedirs(os.path.join('validation', class_name), exist_ok=True)\n",
    "    os.makedirs(os.path.join('test', class_name), exist_ok=True)\n",
    "\n",
    "    # Copy images to the respective directories\n",
    "    for image in train_images:\n",
    "        src = os.path.join(class_dir, image)\n",
    "        dest = os.path.join('train', class_name, image)\n",
    "        shutil.copy(src, dest)\n",
    "\n",
    "    for image in validation_images:\n",
    "        src = os.path.join(class_dir, image)\n",
    "        dest = os.path.join('validation', class_name, image)\n",
    "        shutil.copy(src, dest)\n",
    "\n",
    "    for image in test_images:\n",
    "        src = os.path.join(class_dir, image)\n",
    "        dest = os.path.join('test', class_name, image)\n",
    "        shutil.copy(src, dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb1a33b",
   "metadata": {},
   "source": [
    "# Loading a Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e8ea555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b343759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=len(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16848900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3759 images belonging to 90 classes.\n",
      "Found 805 images belonging to 90 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define the data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'train',\n",
    "    target_size=(224, 224),  # Adjust the target size as needed\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    'validation',\n",
    "    target_size=(224, 224),  # Adjust the target size as needed\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4ca9f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained MobileNetV2 model\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca44338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom layers for your classification task\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "predictions = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2cb47c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd6a02a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "118/118 [==============================] - 622s 5s/step - loss: 2.9379 - accuracy: 0.4195 - val_loss: 1.5316 - val_accuracy: 0.6758\n",
      "Epoch 2/10\n",
      "118/118 [==============================] - 526s 4s/step - loss: 0.6230 - accuracy: 0.8731 - val_loss: 1.0557 - val_accuracy: 0.7503\n",
      "Epoch 3/10\n",
      "118/118 [==============================] - 478s 4s/step - loss: 0.2070 - accuracy: 0.9691 - val_loss: 0.8060 - val_accuracy: 0.8112\n",
      "Epoch 4/10\n",
      "118/118 [==============================] - 878s 7s/step - loss: 0.0899 - accuracy: 0.9944 - val_loss: 0.6818 - val_accuracy: 0.8323\n",
      "Epoch 5/10\n",
      "118/118 [==============================] - 1075s 9s/step - loss: 0.0430 - accuracy: 0.9979 - val_loss: 0.6450 - val_accuracy: 0.8323\n",
      "Epoch 6/10\n",
      "118/118 [==============================] - 1038s 9s/step - loss: 0.0315 - accuracy: 0.9979 - val_loss: 0.5807 - val_accuracy: 0.8435\n",
      "Epoch 7/10\n",
      "118/118 [==============================] - 584s 5s/step - loss: 0.0202 - accuracy: 0.9997 - val_loss: 0.5425 - val_accuracy: 0.8534\n",
      "Epoch 8/10\n",
      "118/118 [==============================] - 463s 4s/step - loss: 0.0155 - accuracy: 0.9995 - val_loss: 0.5186 - val_accuracy: 0.8534\n",
      "Epoch 9/10\n",
      "118/118 [==============================] - 456s 4s/step - loss: 0.0123 - accuracy: 0.9989 - val_loss: 0.5026 - val_accuracy: 0.8596\n",
      "Epoch 10/10\n",
      "118/118 [==============================] - 844s 7s/step - loss: 0.0097 - accuracy: 0.9995 - val_loss: 0.4874 - val_accuracy: 0.8534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x17df48a1d20>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_generator, validation_data=validation_generator, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e801164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "Predicted class label: Egyptian_cat\n",
      "Confidence: 0.36\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "# Load a pre-trained MobileNetV2 model (you can replace this with your custom model)\n",
    "model = MobileNetV2(weights='imagenet')  # You can replace 'imagenet' with your custom model file if applicable.\n",
    "\n",
    "# Define a function to preprocess an image for model input\n",
    "def preprocess_image(image_path):\n",
    "    img = image.load_img(image_path, target_size=(224, 224))  # Adjust target_size to match your model's requirements.\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "# Path to the image you want to classify\n",
    "image_path =r\"C:\\Users\\sandeep\\OneDrive\\Desktop\\Navya_files\\Mini Project\\validation\\cat\\5e07a0666d.jpg\"  # Replace with the actual path to your image.\n",
    "\n",
    "# Preprocess the image\n",
    "preprocessed_image = preprocess_image(image_path)\n",
    "\n",
    "# Make predictions on the preprocessed image\n",
    "predictions = model.predict(preprocessed_image)\n",
    "\n",
    "# Decode the predictions to get class labels and probabilities\n",
    "decoded_predictions = decode_predictions(predictions, top=1)  # You can adjust 'top' to get more or fewer predictions.\n",
    "\n",
    "# Get the top predicted class label and its probability\n",
    "predicted_class_label = decoded_predictions[0][0][1]\n",
    "confidence = decoded_predictions[0][0][2]\n",
    "\n",
    "print(f\"Predicted class label: {predicted_class_label}\")\n",
    "print(f\"Confidence: {confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d48e714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandeep\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to 'mobilenet_v2.h5'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import save_model\n",
    "\n",
    "# Load the pre-trained MobileNetV2 model\n",
    "model = MobileNetV2(weights='imagenet')\n",
    "\n",
    "# Save the model to an HDF5 file\n",
    "model.save('mobilenet_v2.h5')\n",
    "\n",
    "print(\"Model saved to 'mobilenet_v2.h5'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15318c29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
